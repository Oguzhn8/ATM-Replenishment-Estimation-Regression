# ATM-Replenishment-Estimation-Regression
In this study, last two-week cash replenishment estimation was made for various ATMs from approximately 2 years of data.
## Dataset
The dataset contains 57 columns. While 2 columns contain ATM id and date information, the remaining 55 columns contain various information for the relevant ATM. Column names, number of non-null records and data types can be seen in the following table. <br/>
![image](https://user-images.githubusercontent.com/78887209/225242958-551a5a92-bb7e-4775-ad03-470e9ec59870.png) <br/>
It is noticed that there are NULL records in columns 42-52. The NULL Handling process will be discussed in the following sections. <br/> 
### Creating Target Variable
When the columns in the data set were examined, it was noticed that there was no ready target variable. For this reason, the money requirement for each ATM on the relevant day was created using the relevant columns in the data set. The data set includes the total amount of withdrawals and deposits of banknotes in circulation. This information is kept in deposit_5,withdrawal_5 etc columns. In addition, the 'using_taken_money' column contains the information whether the relevant ATM can recirculate the deposited money. Using this information, the target variable was created with the help of the following codes.  <br/>
![image](https://user-images.githubusercontent.com/78887209/225249169-93888cdf-8fcb-4e67-bf91-fd4a0e1cf12f.png) <br/>
If the relevant ATM can use the money it has received, the amount of money required for the relevant ATM is found by subtracting the money deposited from the withdrawn money. On the other hand, if the relevant ATM cannot use the money it has received, the money withdrawn directly is collected and the required amount of money is found.
In addition, the 'total withdrawal' and 'total deposit' columns created during the target variable generation process were also included in the variable set.
### Changing the time frequency of the dataset
The first few rows of the dataset can be seen in the figure below <br/>
![image](https://user-images.githubusercontent.com/78887209/225243596-06e88bc1-48d9-4094-844a-20de11718eef.png) <br/>
As can be seen from the figure, the data set contains information at daily frequency. In order to make weekly money replenishment estimation for the relevant ATM, the table must be arranged with a weekly frequency. While the data set is updated on a weekly basis, each column should be arranged according to the characteristics of the column. For example, columns that do not change on a daily basis and are specific to ATMs (eg nof_food, nof_deposit_casset) can be imported into the table on a weekly basis unchanged. Since the columns containing the withdrawal/deposit amounts of the banknotes in circulation and target variable change on a daily basis, they have been added to the new table by taking the weekly average. Finally, 5 categorical variables (official_holiday, special_day, holiday_before_after, is_workday, atm_place) in the data set were added to the weekly table by taking the mode value of the relevant week. The day_of_month column has been omitted from the data set as it will not make sense in the weekly data. The column week_of_month containing the week information in the relevant month, month_of_year containing the month information in the related year, and week_of_year containing the week information in the related year are included in the data set. <br/>
Daily table 'initial_data.xlsx' and weekly table 'weekly_data.xlsx' are available in excel.

## Data Preprocessing
During the data preprocessing phase, the NULL imputation process will be carried out for the columns containing NULL values mentioned in the previous section, and the encoding methods for categorical variables will be discussed. In the data preprocessing stage, NULL assignment will be made for columns containing NULL values mentioned in the previous section, and coding methods for categorical variables will be discussed. The methods to be discussed were applied on the training set of the model in order to prevent the problem of data leakage. Data leakage is when information from outside the training dataset is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the mode being constructed.
### Encoding Categorical Variables
There are 5 categorical variables in the data set. The number of unique values in each categorical variable is important for the encoding method to be applied. The chart below shows the categorical variables and unique value numbers in the data set. 
![image](https://user-images.githubusercontent.com/78887209/225440140-226fb1d6-266f-40f3-934c-261a70050901.png) <br/>
One hot encoding method is applied for categorical variables with less than 10 unique values. On the other hand, for categorical variables with more than 10 unique values, one hot encoding method can greatly enlarge the data set, so an alternative method, Target Encoding, has been applied. <br/>
#### Target Encoding
A feature with a large number of categories can be troublesome to encode: a one-hot encoding would generate too many features and alternatives, like a label encoding, might not be appropriate for that feature. A target encoding derives numbers for the categories using the feature's most important property: its relationship with the target. Target encoding is the process of replacing a categorical value with the mean of the target variable. The target variable mean of the relevant categorical variable in the data set is found and the categorical variable is replace with the mean value.
### NULL Imputation
It has been noticed that there are NULL values in 11 variables in the data set. The NULL numbers in the training set are as follows. <br/>
![image](https://user-images.githubusercontent.com/78887209/225448413-6adcd43f-bf6d-41b2-b535-0802e9398308.png) <br/> 
There are 670 rows in the training set, any of which is NULL. This information shows that in rows where any of the related variables are not NULL, none of them are NULL. The ATM codes where the respective variables get NULL values are 1, 512, 491, 133, 537, 539, 547, 549, 459, 429, and 656. When the time series of ATMs are examined, it is noticed that the related variables do not take any value other than NULL on any date. For this reason, the related variables were subjected to the NULL imputation process by means of the KNN Imputer method.
#### KNN Imputer
KNNimputer is a multivariate method used to fill out or predict the missing values in a dataset. It is a more useful method that works on the basic approach of the KNN algorithm by using variables that may be related to each other instead of the naive approach where all values are filled with the mean or median. In this approach, firstly specify a distance from the missing values which is also known as the K parameter. The missing value will be predicted in reference to the mean of the neighbours. Apart from 11 variables containing NULL values, 40 variables were used in NULL imputation. The number of neighborhoods was determined as 7, which is the approximate square root of 51 variables to be used in KNN.
## Feature Elimination Steps
